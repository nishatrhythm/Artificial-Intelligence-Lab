{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3e0d6a-f570-4980-a9eb-3ca76c28db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with initial weights and bias: 4.8\n"
     ]
    }
   ],
   "source": [
    "#a simple neural network with one output neuron, four inputs and weights, and bias\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "output = (inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + inputs[3] * weights[3] + bias)\n",
    "print(\"Output with initial weights and bias:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b772d18-9f85-4b49-8fb5-d07a07283f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with adjusted weights and bias: 2.3580773913953754\n"
     ]
    }
   ],
   "source": [
    "# Design the previous example of neural network by adjusting weights and bias randomly\n",
    "\n",
    "import random\n",
    "for i in range(len(weights)):\n",
    "    weights[i] += random.uniform(-0.5, 0.5)\n",
    "bias += random.uniform(-0.5, 0.5)\n",
    "\n",
    "# Calculate output with adjusted weights and bias\n",
    "output = (inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + inputs[3] * weights[3] + bias)\n",
    "print(\"Output with adjusted weights and bias:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e095ca7-e207-44ea-8aa3-5836796e02bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "# A fully connected neural network — every neuron in the current layer has connections to every neuron from the previous layer.\n",
    "\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "    # Neuron 1:\n",
    "    inputs[0] * weights1[0] + inputs[1] * weights1[1] + inputs[2] * weights1[2] + inputs[3] * weights1[3] + bias1,\n",
    "\n",
    "    # Neuron 2:\n",
    "    inputs[0] * weights2[0] + inputs[1] * weights2[1] + inputs[2] * weights2[2] + inputs[3] * weights2[3] + bias2,\n",
    "\n",
    "    # Neuron 3:\n",
    "    inputs[0] * weights3[0] + inputs[1] * weights3[1] + inputs[2] * weights3[2] + inputs[3] * weights3[3] + bias3]\n",
    "\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2c2577-fb13-4e16-a54b-14f6c92a0ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: -3.0991066012210022\n"
     ]
    }
   ],
   "source": [
    "# A fully connected neural network — every neuron in the current layer has connections to every neuron from the previous layer.\n",
    "# You have 4 input neurons, one hidden layer consisting of 3 neurons and one output neuron. You should adust weights and biases randomly.\n",
    "\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "# Randomly initialize weights and biases for the hidden layer\n",
    "hidden_weights = [[random.uniform(-1, 1) for _ in range(4)] for _ in range(3)]\n",
    "hidden_biases = [random.uniform(-1, 1) for _ in range(3)]\n",
    "\n",
    "# Randomly initialize weights and bias for the output layer\n",
    "output_weights = [random.uniform(-1, 1) for _ in range(3)]\n",
    "output_bias = random.uniform(-1, 1)\n",
    "\n",
    "# Calculate outputs for the hidden layer\n",
    "hidden_outputs = [\n",
    "    sum([inputs[i] * hidden_weights[j][i] for i in range(4)]) + hidden_biases[j]\n",
    "    for j in range(3)\n",
    "]\n",
    "\n",
    "# Calculate output for the output layer\n",
    "output = sum([hidden_outputs[j] * output_weights[j] for j in range(3)]) + output_bias\n",
    "\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770a2ab7-4aae-4fc4-96a8-88e17fe93570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1.2355\n"
     ]
    }
   ],
   "source": [
    "# Using loop option to get the weights, inputs and biases then feed into the neurons.\n",
    "\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "           [0.2, 0.8, -0.5, 1],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]\n",
    "          ]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Output of the current layer\n",
    "layer_outputs = []\n",
    "\n",
    "# For each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    # Zeroed output of the given neuron\n",
    "    neuron_output = 0\n",
    "\n",
    "    # For each input and weight to the neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        # Multiply this input by the associated weight\n",
    "        # and add to the neuron's output variable\n",
    "\n",
    "        neuron_output += n_input * weight\n",
    "\n",
    "    # Add bias\n",
    "    neuron_output += neuron_bias\n",
    "\n",
    "    # Put the neuron's result into the layer's output list\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "#print(layer_outputs)\n",
    "weight_out = [0.2, 0.8, -0.5]\n",
    "bias_out = 0.5\n",
    "final_output = (layer_outputs[0] * weight_out[0] + layer_outputs[1] * weight_out[1] + layer_outputs[2] * weight_out[2]) + bias_out\n",
    "print(\"Output:\", final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e09e10-2849-4d5e-bf8d-00436cbcff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 4.8\n"
     ]
    }
   ],
   "source": [
    "# Using numpy library to calculate dot product in the neural network.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173fcef4-9699-4f92-b9b0-c90a459a07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = np.dot(weights, inputs) + biases\n",
    "# or\n",
    "# outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d22214-e8c4-41a1-895e-7181bc3c784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "# Same code while multiplying the inputs with transpose of the weights to adjust the matrix row column multiplication concept\n",
    "\n",
    "inputs = np.array([1, 2, 3, 2.5])\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "])\n",
    "biases = np.array([2, 3, 0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "print(\"Output:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f02ab3-9570-4b42-8f11-0cffef8ad2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "# Take inputs containing 3 samples with 4 features, and 3 neurons with weights and biases, respectively.\n",
    "# Then print the outputs of the neorons.\n",
    "\n",
    "# Define inputs (3 samples with 4 features each)\n",
    "inputs = np.array([\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2.0, 5.0, -1.0, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "])\n",
    "\n",
    "# Define weights (3 neurons with 4 weights each)\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "])\n",
    "\n",
    "# Define biases (3 biases, one for each neuron)\n",
    "biases = np.array([2, 3, 0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cb987c-f41e-4e63-9d63-f8cd8a80b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8  -1.15  1.95]\n",
      " [ 6.85 -2.55  3.05]\n",
      " [ 5.8  -1.95  2.9 ]\n",
      " [ 4.8  -1.15  1.95]\n",
      " [ 5.8  -1.95  2.9 ]]\n"
     ]
    }
   ],
   "source": [
    "# inputs-batch with weights and then transpose them to calculate dot product.\n",
    "\n",
    "# inputs = [[1.0, 2.0, 3.0, 2.5], [2.0, 4.0, 1.5, 2.0], [0.5, 1.5, 2.0, 3.5]]\n",
    "# weights = [[0.2, 0.8, -0.5, 1.0], [0.5, -0.9, 0.3, -0.7], [-0.1, 0.6, -0.3, 0.9]]\n",
    "\n",
    "inputs = np.array([[1.0, 2.0, 3.0, 2.5],\n",
    "                   [2.0, 4.0, 1.5, 2.0],\n",
    "                   [0.5, 1.5, 2.0, 3.5],\n",
    "                   [1.0, 2.0, 3.0, 2.5],\n",
    "                   [0.5, 1.5, 2.0, 3.5]])\n",
    "\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1.0],\n",
    "                    [0.5, -0.9, 0.3, -0.7],\n",
    "                    [-0.1, 0.6, -0.3, 0.9]])\n",
    "\n",
    "biases = np.array([2.0, 1.0, -0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T)+biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b0296f-676e-47b3-b180-e7618d0de595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]\n",
      " [-1.67008  1.29842  0.83314]]\n"
     ]
    }
   ],
   "source": [
    "# Two hidden layers with four neurons at the first layer and three in the second.\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2., 5., -1., 2],\n",
    "          [-1.5, 2.7, 3.3, -0.8],\n",
    "          [3, 2, 1.7, -0.5]\n",
    "          ]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "           [0.5, -0.91, 0.26, -0.5],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "            [-0.5, 0.12, -0.33],\n",
    "            [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5d13f06-09e5-45f1-b05d-7056c4fd7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62245933 0.26894142 0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoidal activation function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example usage\n",
    "x = np.array([0.5, -1.0, 2.0])\n",
    "output = sigmoid(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea82b57a-6bb5-4e6f-98de-18eff6524d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Rectified Linear Unit (ReLU) activation function\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
    "output = relu(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f142b36-fc52-41eb-9e9a-1d02a79a2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Step function\n",
    "\n",
    "def step_function(x, threshold=0):\n",
    "    if x <= threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Example usage\n",
    "x = 0.5\n",
    "output = step_function(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe45c7b2-39ac-43fa-8b18-67b7b38d006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Step function (while passing array)\n",
    "\n",
    "def step_function(x, threshold=0):\n",
    "    return np.where(x <= threshold, 0, 1)\n",
    "\n",
    "# Example usage\n",
    "x = np.array([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
    "output = step_function(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "804fdd54-9437-47fe-afad-c62e4e5b1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the Neural Network: [[0.60690482]\n",
      " [0.60690482]\n",
      " [0.60690482]\n",
      " [0.60690482]\n",
      " [0.60690482]\n",
      " [0.60690482]\n",
      " [0.61071525]\n",
      " [0.61647801]\n",
      " [0.62288921]\n",
      " [0.60690482]]\n"
     ]
    }
   ],
   "source": [
    "# Design a neural network that has four input neurons, two hidden layers, and one output layer neuron.\n",
    "# The activation function in the output payer should be sigmoidal. You should also adjust the weights and biases randomly.\n",
    "# Moreover, the input dataset should contain 10 samples.\n",
    "\n",
    "# Define the number of samples and features for the input layer\n",
    "num_samples = 10\n",
    "num_features = 4\n",
    "\n",
    "# Generate a random input dataset with 10 samples and 4 features\n",
    "np.random.seed(0)  # For reproducibility\n",
    "inputs = np.random.rand(num_samples, num_features)\n",
    "\n",
    "# Initialize weights and biases randomly for each layer\n",
    "# Hidden Layer 1: 4 inputs -> 3 neurons\n",
    "weights_hidden_1 = np.random.uniform(-1, 1, (num_features, 3))\n",
    "biases_hidden_1 = np.random.uniform(-1, 1, (1, 3))\n",
    "\n",
    "# Hidden Layer 2: 3 inputs -> 3 neurons\n",
    "weights_hidden_2 = np.random.uniform(-1, 1, (3, 3))\n",
    "biases_hidden_2 = np.random.uniform(-1, 1, (1, 3))\n",
    "\n",
    "# Output Layer: 3 inputs -> 1 neuron\n",
    "weights_output = np.random.uniform(-1, 1, (3, 1))\n",
    "biases_output = np.random.uniform(-1, 1, (1, 1))\n",
    "\n",
    "# Define the activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Perform the forward pass\n",
    "# Hidden Layer 1\n",
    "hidden_layer_1_output = relu(np.dot(inputs, weights_hidden_1) + biases_hidden_1)\n",
    "\n",
    "# Hidden Layer 2\n",
    "hidden_layer_2_output = relu(np.dot(hidden_layer_1_output, weights_hidden_2) + biases_hidden_2)\n",
    "\n",
    "# Output Layer\n",
    "output_layer_output = sigmoid(np.dot(hidden_layer_2_output, weights_output) + biases_output)\n",
    "\n",
    "# Print the outputs of the output layer\n",
    "print(\"Output of the Neural Network:\", output_layer_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
