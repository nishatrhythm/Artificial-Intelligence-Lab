{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda211f7-7cba-4a2d-98d5-6ae69418b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset using pandas for the following attbituts and then predict the housing prices using neural network:\n",
    "\n",
    "# Area: The total area of the house in square feet\n",
    "# Bedrooms: The number of bedrooms in the house.\n",
    "# Bathrooms: The number of bathrooms in the house.\n",
    "# Age: The age of the house in years.\n",
    "# Location: The neighborhood or area where the house is located.\n",
    "# Garage Size: The size of the garage in square feet.\n",
    "# Yard Size: The size of the yard or outdoor space in square feet.\n",
    "# Amenities: A binary feature indicating whether the house has additional amenities such as a swimming pool, gym, etc.\n",
    "# School Rating: The rating of nearby schools, on a scale from 1 to 10.\n",
    "# Distance to City Center: The distance of the house from the city center in miles.\n",
    "# Price: The selling price of the house.\n",
    "\n",
    "# dataset example:\n",
    "# data = { 'Area': [2000, 1800, 2500, 2200, 1900, 2800, 2100, 1700, 2400, 2000],\n",
    "#         'Bedrooms': [3, 2, 4, 3, 2, 5, 4, 2, 3, 3],\n",
    "#         'Bathrooms': [2, 1.5, 3, 2.5, 2, 3.5, 2.5, 1, 3, 2],\n",
    "#         'Age': [10, 5, 15, 8, 3, 20, 12, 6, 18, 9],\n",
    "#         'Location': ['Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban'],\n",
    "#         'Garage_Size': [400, 300, 500, 450, 350, 600, 400, 250, 550, 400],\n",
    "#         'Yard_Size': [800, 600, 1000, 900, 700, 1200, 800, 500, 1100, 800],\n",
    "#         'Amenities': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "#         'School_Rating': [8, 7, 6, 9, 8, 5, 7, 6, 4, 8],\n",
    "#         'Distance_to_City_Center': [5, 2, 10, 7, 4, 15, 6, 3, 12, 5],\n",
    "#         'Price': [300000, 250000, 350000, 320000, 280000, 400000, 310000, 240000, 370000, 300000]\n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a430322f-1b66-43a0-9fb9-f0f8650eeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('housing_data.csv')\n",
    "# print(data.head())  # Prints the first 5 rows of the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9e6796-4325-454f-8576-15dc83c8bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "data = {\n",
    "    'Area': [2000, 1800, 2500, 2200, 1900, 2800, 2100, 1700, 2400, 2000],\n",
    "    'Bedrooms': [3, 2, 4, 3, 2, 5, 4, 2, 3, 3],\n",
    "    'Bathrooms': [2, 1.5, 3, 2.5, 2, 3.5, 2.5, 1, 3, 2],\n",
    "    'Age': [10, 5, 15, 8, 3, 20, 12, 6, 18, 9],\n",
    "    'Location': ['Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban'],\n",
    "    'Garage_Size': [400, 300, 500, 450, 350, 600, 400, 250, 550, 400],\n",
    "    'Yard_Size': [800, 600, 1000, 900, 700, 1200, 800, 500, 1100, 800],\n",
    "    'Amenities': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "    'School_Rating': [8, 7, 6, 9, 8, 5, 7, 6, 4, 8],\n",
    "    'Distance_to_City_Center': [5, 2, 10, 7, 4, 15, 6, 3, 12, 5],\n",
    "    'Price': [300000, 250000, 350000, 320000, 280000, 400000, 310000, 240000, 370000, 300000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fde12be-9798-4b1e-8c1c-3f42e2b3b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab4ad8c-f6a4-4cb2-9158-333cd5f5e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a pandas DataFrame\n",
    "housing_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7e762b-0f9e-44ec-a47c-ce16a1ebe97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3b395d-6ad7-4802-9f84-d848aac88680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Encode the 'Location' column\n",
    "label_encoder = LabelEncoder()\n",
    "housing_data['Location'] = label_encoder.fit_transform(housing_data['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b7bcc7-4319-4d2b-b559-02bc983bb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90148739-2d1a-492b-af18-2fb6a50f74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = housing_data.drop('Price', axis=1)\n",
    "y = housing_data['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c747f24-de43-4f08-9dcf-dd76867789b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82608759-d28f-43d3-8ed0-51acda360a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837939bc-8849-4823-aadf-ecc455f327f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e9fd6c-2f3f-4bc5-92a4-8264a838d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "666cc9e6-75f0-4615-b4ce-0d66a238e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(X_train.shape[1],)),  # Define the input shape separately\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9794b873-8cd1-4395-8126-d5143579b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2e6f78-03db-4428-8507-b9b4d697f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 99749814272.0000 - mae: 311666.4062 - val_loss: 99249946624.0000 - val_mae: 314999.9375\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 99749765120.0000 - mae: 311666.3438 - val_loss: 99249930240.0000 - val_mae: 314999.8750\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 99749732352.0000 - mae: 311666.2812 - val_loss: 99249913856.0000 - val_mae: 314999.8750\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99749699584.0000 - mae: 311666.2188 - val_loss: 99249897472.0000 - val_mae: 314999.8438\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 99749650432.0000 - mae: 311666.1562 - val_loss: 99249897472.0000 - val_mae: 314999.8438\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 99749617664.0000 - mae: 311666.0938 - val_loss: 99249881088.0000 - val_mae: 314999.8125\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 99749560320.0000 - mae: 311666.0312 - val_loss: 99249864704.0000 - val_mae: 314999.7812\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99749519360.0000 - mae: 311665.9688 - val_loss: 99249848320.0000 - val_mae: 314999.7500\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99749486592.0000 - mae: 311665.9062 - val_loss: 99249831936.0000 - val_mae: 314999.7500\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 99749429248.0000 - mae: 311665.8125 - val_loss: 99249815552.0000 - val_mae: 314999.6875\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99749388288.0000 - mae: 311665.7500 - val_loss: 99249790976.0000 - val_mae: 314999.6875\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 99749339136.0000 - mae: 311665.6875 - val_loss: 99249774592.0000 - val_mae: 314999.6250\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 99749298176.0000 - mae: 311665.6250 - val_loss: 99249750016.0000 - val_mae: 314999.6250\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 99749240832.0000 - mae: 311665.5625 - val_loss: 99249741824.0000 - val_mae: 314999.5938\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 99749199872.0000 - mae: 311665.4688 - val_loss: 99249717248.0000 - val_mae: 314999.5625\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 99749167104.0000 - mae: 311665.4062 - val_loss: 99249700864.0000 - val_mae: 314999.5312\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99749109760.0000 - mae: 311665.3438 - val_loss: 99249684480.0000 - val_mae: 314999.5000\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 99749060608.0000 - mae: 311665.2500 - val_loss: 99249668096.0000 - val_mae: 314999.4688\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 99749003264.0000 - mae: 311665.1562 - val_loss: 99249651712.0000 - val_mae: 314999.4375\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99748962304.0000 - mae: 311665.0938 - val_loss: 99249627136.0000 - val_mae: 314999.4062\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 99748904960.0000 - mae: 311665.0000 - val_loss: 99249602560.0000 - val_mae: 314999.3750\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99748839424.0000 - mae: 311664.9062 - val_loss: 99249586176.0000 - val_mae: 314999.3438\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 99748798464.0000 - mae: 311664.8438 - val_loss: 99249569792.0000 - val_mae: 314999.3125\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 99748716544.0000 - mae: 311664.7188 - val_loss: 99249545216.0000 - val_mae: 314999.2812\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99748651008.0000 - mae: 311664.6250 - val_loss: 99249528832.0000 - val_mae: 314999.2500\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 99748601856.0000 - mae: 311664.5312 - val_loss: 99249504256.0000 - val_mae: 314999.2188\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 99748519936.0000 - mae: 311664.4062 - val_loss: 99249471488.0000 - val_mae: 314999.1875\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 99748454400.0000 - mae: 311664.3438 - val_loss: 99249455104.0000 - val_mae: 314999.1250\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 99748405248.0000 - mae: 311664.2188 - val_loss: 99249438720.0000 - val_mae: 314999.1250\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99748323328.0000 - mae: 311664.1250 - val_loss: 99249422336.0000 - val_mae: 314999.0625\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 99748249600.0000 - mae: 311664.0000 - val_loss: 99249389568.0000 - val_mae: 314999.0312\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 99748175872.0000 - mae: 311663.8750 - val_loss: 99249373184.0000 - val_mae: 314999.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99748110336.0000 - mae: 311663.7500 - val_loss: 99249348608.0000 - val_mae: 314998.9688\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 99748028416.0000 - mae: 311663.6250 - val_loss: 99249324032.0000 - val_mae: 314998.9375\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99747946496.0000 - mae: 311663.5312 - val_loss: 99249291264.0000 - val_mae: 314998.8750\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99747864576.0000 - mae: 311663.3750 - val_loss: 99249266688.0000 - val_mae: 314998.8438\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 99747782656.0000 - mae: 311663.2500 - val_loss: 99249242112.0000 - val_mae: 314998.8125\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 99747692544.0000 - mae: 311663.0938 - val_loss: 99249209344.0000 - val_mae: 314998.7500\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 99747594240.0000 - mae: 311662.9688 - val_loss: 99249176576.0000 - val_mae: 314998.6875\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99747495936.0000 - mae: 311662.8125 - val_loss: 99249152000.0000 - val_mae: 314998.6562\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99747405824.0000 - mae: 311662.6562 - val_loss: 99249127424.0000 - val_mae: 314998.6250\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 99747299328.0000 - mae: 311662.5000 - val_loss: 99249094656.0000 - val_mae: 314998.5625\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99747192832.0000 - mae: 311662.3438 - val_loss: 99249061888.0000 - val_mae: 314998.5000\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99747094528.0000 - mae: 311662.1562 - val_loss: 99249029120.0000 - val_mae: 314998.4375\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 99746971648.0000 - mae: 311661.9688 - val_loss: 99248996352.0000 - val_mae: 314998.4062\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 99746865152.0000 - mae: 311661.8125 - val_loss: 99248955392.0000 - val_mae: 314998.3438\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 99746742272.0000 - mae: 311661.6250 - val_loss: 99248914432.0000 - val_mae: 314998.2812\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 99746611200.0000 - mae: 311661.4062 - val_loss: 99248873472.0000 - val_mae: 314998.2188\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99746488320.0000 - mae: 311661.2188 - val_loss: 99248832512.0000 - val_mae: 314998.1562\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 99746349056.0000 - mae: 311661.0000 - val_loss: 99248799744.0000 - val_mae: 314998.0938\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 99746217984.0000 - mae: 311660.7812 - val_loss: 99248758784.0000 - val_mae: 314998.0312\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 99746062336.0000 - mae: 311660.5938 - val_loss: 99248717824.0000 - val_mae: 314997.9688\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 99745931264.0000 - mae: 311660.3438 - val_loss: 99248668672.0000 - val_mae: 314997.8750\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99745767424.0000 - mae: 311660.1250 - val_loss: 99248627712.0000 - val_mae: 314997.8125\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99745628160.0000 - mae: 311659.8750 - val_loss: 99248578560.0000 - val_mae: 314997.7500\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 99745464320.0000 - mae: 311659.6250 - val_loss: 99248529408.0000 - val_mae: 314997.6875\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99745292288.0000 - mae: 311659.3438 - val_loss: 99248480256.0000 - val_mae: 314997.5938\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 99745128448.0000 - mae: 311659.0938 - val_loss: 99248431104.0000 - val_mae: 314997.5000\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99744940032.0000 - mae: 311658.8125 - val_loss: 99248390144.0000 - val_mae: 314997.4375\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 99744768000.0000 - mae: 311658.5312 - val_loss: 99248340992.0000 - val_mae: 314997.3750\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99744571392.0000 - mae: 311658.2500 - val_loss: 99248291840.0000 - val_mae: 314997.2812\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 99744382976.0000 - mae: 311657.9375 - val_loss: 99248226304.0000 - val_mae: 314997.1875\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 99744178176.0000 - mae: 311657.6250 - val_loss: 99248168960.0000 - val_mae: 314997.0938\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99743981568.0000 - mae: 311657.3125 - val_loss: 99248111616.0000 - val_mae: 314997.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 99743760384.0000 - mae: 311656.9688 - val_loss: 99248046080.0000 - val_mae: 314996.9062\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 99743539200.0000 - mae: 311656.6250 - val_loss: 99247988736.0000 - val_mae: 314996.8125\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 99743309824.0000 - mae: 311656.2812 - val_loss: 99247931392.0000 - val_mae: 314996.7188\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 99743096832.0000 - mae: 311655.9062 - val_loss: 99247865856.0000 - val_mae: 314996.6250\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 99742842880.0000 - mae: 311655.5312 - val_loss: 99247816704.0000 - val_mae: 314996.5312\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99742605312.0000 - mae: 311655.1562 - val_loss: 99247734784.0000 - val_mae: 314996.4062\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99742359552.0000 - mae: 311654.7812 - val_loss: 99247677440.0000 - val_mae: 314996.3125\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99742089216.0000 - mae: 311654.3438 - val_loss: 99247603712.0000 - val_mae: 314996.1875\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99741827072.0000 - mae: 311653.9375 - val_loss: 99247538176.0000 - val_mae: 314996.0938\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 99741556736.0000 - mae: 311653.5312 - val_loss: 99247456256.0000 - val_mae: 314995.9688\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 99741278208.0000 - mae: 311653.0938 - val_loss: 99247390720.0000 - val_mae: 314995.8750\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 99740983296.0000 - mae: 311652.6250 - val_loss: 99247325184.0000 - val_mae: 314995.7500\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99740688384.0000 - mae: 311652.1562 - val_loss: 99247243264.0000 - val_mae: 314995.6250\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 99740385280.0000 - mae: 311651.6875 - val_loss: 99247161344.0000 - val_mae: 314995.5000\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 99740065792.0000 - mae: 311651.2188 - val_loss: 99247087616.0000 - val_mae: 314995.3750\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99739762688.0000 - mae: 311650.7188 - val_loss: 99246997504.0000 - val_mae: 314995.2500\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99739435008.0000 - mae: 311650.1562 - val_loss: 99246907392.0000 - val_mae: 314995.0938\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 99739099136.0000 - mae: 311649.6562 - val_loss: 99246833664.0000 - val_mae: 314994.9688\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 99738746880.0000 - mae: 311649.1250 - val_loss: 99246735360.0000 - val_mae: 314994.8125\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 99738394624.0000 - mae: 311648.5625 - val_loss: 99246653440.0000 - val_mae: 314994.6875\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99738034176.0000 - mae: 311647.9688 - val_loss: 99246563328.0000 - val_mae: 314994.5625\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 99737640960.0000 - mae: 311647.3750 - val_loss: 99246465024.0000 - val_mae: 314994.3750\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 99737272320.0000 - mae: 311646.7812 - val_loss: 99246366720.0000 - val_mae: 314994.2500\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99736887296.0000 - mae: 311646.1875 - val_loss: 99246276608.0000 - val_mae: 314994.0938\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 99736485888.0000 - mae: 311645.5625 - val_loss: 99246178304.0000 - val_mae: 314993.9375\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 99736068096.0000 - mae: 311644.9062 - val_loss: 99246071808.0000 - val_mae: 314993.7500\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 99735633920.0000 - mae: 311644.2500 - val_loss: 99245965312.0000 - val_mae: 314993.6250\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 99735207936.0000 - mae: 311643.5625 - val_loss: 99245850624.0000 - val_mae: 314993.4375\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 99734757376.0000 - mae: 311642.8438 - val_loss: 99245752320.0000 - val_mae: 314993.2500\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 99734323200.0000 - mae: 311642.1562 - val_loss: 99245645824.0000 - val_mae: 314993.0938\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99733839872.0000 - mae: 311641.4062 - val_loss: 99245531136.0000 - val_mae: 314992.9062\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 99733372928.0000 - mae: 311640.6875 - val_loss: 99245424640.0000 - val_mae: 314992.7500\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 99732881408.0000 - mae: 311639.9062 - val_loss: 99245309952.0000 - val_mae: 314992.5625\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 99732381696.0000 - mae: 311639.1250 - val_loss: 99245178880.0000 - val_mae: 314992.3438\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 99731873792.0000 - mae: 311638.2812 - val_loss: 99245056000.0000 - val_mae: 314992.1562\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 99731349504.0000 - mae: 311637.4688 - val_loss: 99244933120.0000 - val_mae: 314991.9375\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "057f08dd-57c2-4f3e-b1c8-1912260dc803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 99677151232.0000 - mae: 309962.7812\n",
      "Mean Absolute Error on test set: 309962.78125\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Absolute Error on test set: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7c14300-9b65-4983-aaaa-fe6a463d3d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Predicted Prices: [[35.29765 ]\n",
      " [39.143463]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the prices for the test set\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predicted Prices:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33bd8a3d-4430-464d-932c-ed8c7c0a0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c361794-fb16-4a9d-ae85-fb4b70938472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set: 99677155393.01178\n",
      "R-squared on test set: -26.68809700012207\n"
     ]
    }
   ],
   "source": [
    "# Calculate additional metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error on test set: {mse}\")\n",
    "print(f\"R-squared on test set: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
