{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccd92b7-2318-4052-b931-e0b6d2278d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.563\n",
      "Epoch 10 loss: 0.440\n",
      "Epoch 20 loss: 0.326\n",
      "Epoch 30 loss: 0.261\n",
      "Epoch 40 loss: 0.208\n",
      "Epoch 50 loss: 0.165\n",
      "Epoch 60 loss: 0.131\n",
      "Epoch 70 loss: 0.106\n",
      "Epoch 80 loss: 0.087\n",
      "Epoch 90 loss: 0.073\n",
      "Epoch 100 loss: 0.062\n",
      "Epoch 110 loss: 0.054\n",
      "Epoch 120 loss: 0.047\n",
      "Epoch 130 loss: 0.041\n",
      "Epoch 140 loss: 0.037\n",
      "Epoch 150 loss: 0.033\n",
      "Epoch 160 loss: 0.030\n",
      "Epoch 170 loss: 0.027\n",
      "Epoch 180 loss: 0.025\n",
      "Epoch 190 loss: 0.023\n",
      "Epoch 200 loss: 0.021\n",
      "Epoch 210 loss: 0.020\n",
      "Epoch 220 loss: 0.018\n",
      "Epoch 230 loss: 0.017\n",
      "Epoch 240 loss: 0.016\n",
      "Epoch 250 loss: 0.015\n",
      "Epoch 260 loss: 0.014\n",
      "Epoch 270 loss: 0.014\n",
      "Epoch 280 loss: 0.013\n",
      "Epoch 290 loss: 0.012\n",
      "Epoch 300 loss: 0.012\n",
      "Epoch 310 loss: 0.011\n",
      "Epoch 320 loss: 0.011\n",
      "Epoch 330 loss: 0.010\n",
      "Epoch 340 loss: 0.010\n",
      "Epoch 350 loss: 0.010\n",
      "Epoch 360 loss: 0.009\n",
      "Epoch 370 loss: 0.009\n",
      "Epoch 380 loss: 0.009\n",
      "Epoch 390 loss: 0.008\n",
      "Epoch 400 loss: 0.008\n",
      "Epoch 410 loss: 0.008\n",
      "Epoch 420 loss: 0.007\n",
      "Epoch 430 loss: 0.007\n",
      "Epoch 440 loss: 0.007\n",
      "Epoch 450 loss: 0.007\n",
      "Epoch 460 loss: 0.007\n",
      "Epoch 470 loss: 0.006\n",
      "Epoch 480 loss: 0.006\n",
      "Epoch 490 loss: 0.006\n",
      "Epoch 500 loss: 0.006\n",
      "Epoch 510 loss: 0.006\n",
      "Epoch 520 loss: 0.006\n",
      "Epoch 530 loss: 0.005\n",
      "Epoch 540 loss: 0.005\n",
      "Epoch 550 loss: 0.005\n",
      "Epoch 560 loss: 0.005\n",
      "Epoch 570 loss: 0.005\n",
      "Epoch 580 loss: 0.005\n",
      "Epoch 590 loss: 0.005\n",
      "Epoch 600 loss: 0.005\n",
      "Epoch 610 loss: 0.005\n",
      "Epoch 620 loss: 0.004\n",
      "Epoch 630 loss: 0.004\n",
      "Epoch 640 loss: 0.004\n",
      "Epoch 650 loss: 0.004\n",
      "Epoch 660 loss: 0.004\n",
      "Epoch 670 loss: 0.004\n",
      "Epoch 680 loss: 0.004\n",
      "Epoch 690 loss: 0.004\n",
      "Epoch 700 loss: 0.004\n",
      "Epoch 710 loss: 0.004\n",
      "Epoch 720 loss: 0.004\n",
      "Epoch 730 loss: 0.004\n",
      "Epoch 740 loss: 0.004\n",
      "Epoch 750 loss: 0.004\n",
      "Epoch 760 loss: 0.003\n",
      "Epoch 770 loss: 0.003\n",
      "Epoch 780 loss: 0.003\n",
      "Epoch 790 loss: 0.003\n",
      "Epoch 800 loss: 0.003\n",
      "Epoch 810 loss: 0.003\n",
      "Epoch 820 loss: 0.003\n",
      "Epoch 830 loss: 0.003\n",
      "Epoch 840 loss: 0.003\n",
      "Epoch 850 loss: 0.003\n",
      "Epoch 860 loss: 0.003\n",
      "Epoch 870 loss: 0.003\n",
      "Epoch 880 loss: 0.003\n",
      "Epoch 890 loss: 0.003\n",
      "Epoch 900 loss: 0.003\n",
      "Epoch 910 loss: 0.003\n",
      "Epoch 920 loss: 0.003\n",
      "Epoch 930 loss: 0.003\n",
      "Epoch 940 loss: 0.003\n",
      "Epoch 950 loss: 0.003\n",
      "Epoch 960 loss: 0.003\n",
      "Epoch 970 loss: 0.003\n",
      "Epoch 980 loss: 0.003\n",
      "Epoch 990 loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "# source doce: https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "\n",
    "  *** DISCLAIMER ***:\n",
    "  The code below is intended to be simple and educational, NOT optimal.\n",
    "  Real neural net code looks nothing like this. DO NOT use this code.\n",
    "  Instead, read/run it to understand how this specific network works.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "\n",
    "    # Biases\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    return o1\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "    - all_y_trues is a numpy array with n elements.\n",
    "      Elements in all_y_trues correspond to those in data.\n",
    "    '''\n",
    "    learn_rate = 0.1\n",
    "    epochs = 1000 # number of times to loop through the entire dataset\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "\n",
    "        # --- Calculate partial derivatives.\n",
    "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "\n",
    "        # Neuron o1\n",
    "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Neuron h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "        # Neuron h2\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Neuron h1\n",
    "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "        # Neuron h2\n",
    "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "        # Neuron o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "      # --- Calculate total loss at the end of each epoch\n",
    "      if epoch % 10 == 0:\n",
    "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "        loss = mse_loss(all_y_trues, y_preds)\n",
    "        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "\n",
    "\n",
    "# Define dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "# Train our neural network!\n",
    "network = OurNeuralNetwork()\n",
    "network.train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fae382-adaa-41ef-9932-cd4bb1d975fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily: 0.948\n",
      "Frank: 0.041\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "emily = np.array([-7, -3]) # 128 pounds, 63 inches\n",
    "frank = np.array([20, 2])  # 155 pounds, 68 inches\n",
    "print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cfd33b-176b-4eaa-9943-5282bfec75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.148\n",
      "Epoch 10 loss: 0.110\n",
      "Epoch 20 loss: 0.085\n",
      "Epoch 30 loss: 0.067\n",
      "Epoch 40 loss: 0.054\n",
      "Epoch 50 loss: 0.045\n",
      "Epoch 60 loss: 0.038\n",
      "Epoch 70 loss: 0.032\n",
      "Epoch 80 loss: 0.028\n",
      "Epoch 90 loss: 0.024\n",
      "Epoch 100 loss: 0.022\n",
      "Epoch 110 loss: 0.019\n",
      "Epoch 120 loss: 0.017\n",
      "Epoch 130 loss: 0.016\n",
      "Epoch 140 loss: 0.014\n",
      "Epoch 150 loss: 0.013\n",
      "Epoch 160 loss: 0.012\n",
      "Epoch 170 loss: 0.011\n",
      "Epoch 180 loss: 0.011\n",
      "Epoch 190 loss: 0.010\n",
      "Epoch 200 loss: 0.009\n",
      "Epoch 210 loss: 0.009\n",
      "Epoch 220 loss: 0.008\n",
      "Epoch 230 loss: 0.008\n",
      "Epoch 240 loss: 0.008\n",
      "Epoch 250 loss: 0.007\n",
      "Epoch 260 loss: 0.007\n",
      "Epoch 270 loss: 0.007\n",
      "Epoch 280 loss: 0.006\n",
      "Epoch 290 loss: 0.006\n",
      "Epoch 300 loss: 0.006\n",
      "Epoch 310 loss: 0.006\n",
      "Epoch 320 loss: 0.005\n",
      "Epoch 330 loss: 0.005\n",
      "Epoch 340 loss: 0.005\n",
      "Epoch 350 loss: 0.005\n",
      "Epoch 360 loss: 0.005\n",
      "Epoch 370 loss: 0.005\n",
      "Epoch 380 loss: 0.004\n",
      "Epoch 390 loss: 0.004\n",
      "Epoch 400 loss: 0.004\n",
      "Epoch 410 loss: 0.004\n",
      "Epoch 420 loss: 0.004\n",
      "Epoch 430 loss: 0.004\n",
      "Epoch 440 loss: 0.004\n",
      "Epoch 450 loss: 0.004\n",
      "Epoch 460 loss: 0.004\n",
      "Epoch 470 loss: 0.003\n",
      "Epoch 480 loss: 0.003\n",
      "Epoch 490 loss: 0.003\n",
      "Epoch 500 loss: 0.003\n",
      "Epoch 510 loss: 0.003\n",
      "Epoch 520 loss: 0.003\n",
      "Epoch 530 loss: 0.003\n",
      "Epoch 540 loss: 0.003\n",
      "Epoch 550 loss: 0.003\n",
      "Epoch 560 loss: 0.003\n",
      "Epoch 570 loss: 0.003\n",
      "Epoch 580 loss: 0.003\n",
      "Epoch 590 loss: 0.003\n",
      "Epoch 600 loss: 0.003\n",
      "Epoch 610 loss: 0.003\n",
      "Epoch 620 loss: 0.003\n",
      "Epoch 630 loss: 0.002\n",
      "Epoch 640 loss: 0.002\n",
      "Epoch 650 loss: 0.002\n",
      "Epoch 660 loss: 0.002\n",
      "Epoch 670 loss: 0.002\n",
      "Epoch 680 loss: 0.002\n",
      "Epoch 690 loss: 0.002\n",
      "Epoch 700 loss: 0.002\n",
      "Epoch 710 loss: 0.002\n",
      "Epoch 720 loss: 0.002\n",
      "Epoch 730 loss: 0.002\n",
      "Epoch 740 loss: 0.002\n",
      "Epoch 750 loss: 0.002\n",
      "Epoch 760 loss: 0.002\n",
      "Epoch 770 loss: 0.002\n",
      "Epoch 780 loss: 0.002\n",
      "Epoch 790 loss: 0.002\n",
      "Epoch 800 loss: 0.002\n",
      "Epoch 810 loss: 0.002\n",
      "Epoch 820 loss: 0.002\n",
      "Epoch 830 loss: 0.002\n",
      "Epoch 840 loss: 0.002\n",
      "Epoch 850 loss: 0.002\n",
      "Epoch 860 loss: 0.002\n",
      "Epoch 870 loss: 0.002\n",
      "Epoch 880 loss: 0.002\n",
      "Epoch 890 loss: 0.002\n",
      "Epoch 900 loss: 0.002\n",
      "Epoch 910 loss: 0.002\n",
      "Epoch 920 loss: 0.002\n",
      "Epoch 930 loss: 0.002\n",
      "Epoch 940 loss: 0.002\n",
      "Epoch 950 loss: 0.002\n",
      "Epoch 960 loss: 0.002\n",
      "Epoch 970 loss: 0.002\n",
      "Epoch 980 loss: 0.002\n",
      "Epoch 990 loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "# source doce: https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9\n",
    "\n",
    "import numpy as np\n",
    "rafi=[]\n",
    "shafi=[]\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "\n",
    "  *** DISCLAIMER ***:\n",
    "  The code below is intended to be simple and educational, NOT optimal.\n",
    "  Real neural net code looks nothing like this. DO NOT use this code.\n",
    "  Instead, read/run it to understand how this specific network works.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "\n",
    "    # Biases\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    return o1\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "    - all_y_trues is a numpy array with n elements.\n",
    "      Elements in all_y_trues correspond to those in data.\n",
    "    '''\n",
    "    learn_rate = 0.1\n",
    "    epochs = 1000 # number of times to loop through the entire dataset\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "\n",
    "        # --- Calculate partial derivatives.\n",
    "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "\n",
    "        # Neuron o1\n",
    "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Neuron h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "        # Neuron h2\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Neuron h1\n",
    "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "        # Neuron h2\n",
    "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "        # Neuron o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "      # --- Calculate total loss at the end of each epoch\n",
    "      if epoch % 10 == 0:\n",
    "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "        loss = mse_loss(all_y_trues, y_preds)\n",
    "        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "        rafi.append(epoch)\n",
    "        shafi.append(loss)\n",
    "\n",
    "# Define dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "# Train our neural network!\n",
    "network = OurNeuralNetwork()\n",
    "network.train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c792debe-d0d5-4f88-ba6d-7da8ff43365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23ea88ef610>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure()\n",
    "plt.plot(rafi,shafi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
